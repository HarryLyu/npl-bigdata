{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk.data\n",
    "import logging\n",
    "import numpy as np  # Make sure that numpy is imported\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Download the punkt tokenizer for sentence splitting\n",
    "import nltk.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeled = pd.read_csv(\"labeledTrainData.tsv\", header=0, delimiter=\"\\t\", quoting=2)\n",
    "test = pd.read_csv(\"testData.tsv\", header=0, delimiter=\"\\t\", quoting=2)\n",
    "unlabeled = pd.read_csv(\"unlabeledTrainData.tsv\", header=0, delimiter=\"\\t\", quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "texts = list(labeled.review) + list(test.review) + list(unlabeled.review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_to_wordlist(text):\n",
    "    text = re.sub('n\\'t', ' not', text)\n",
    "    \n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    words = text.lower().split()\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk.data\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "def text_to_sentences(text):\n",
    "    text = BeautifulSoup(text).get_text()\n",
    "    \n",
    "    raw_sentences = tokenizer.tokenize(text.strip())\n",
    "    \n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        if len(raw_sentence) > 0:\n",
    "            sentences.append(text_to_wordlist(raw_sentence))\n",
    "\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 5s, sys: 4.22 s, total: 2min 9s\n",
      "Wall time: 2min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences = []\n",
    "\n",
    "for review in texts:\n",
    "    sentences += text_to_sentences(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1059164"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_features = 300  # итоговая размерность вектора каждого слова\n",
    "min_word_count = 5  # минимальная частотность слова, чтобы оно попало в модель\n",
    "num_workers = 2     # количество ядер вашего процессора, чтоб запустить обучение в несколько потоков\n",
    "context = 10        # размер окна \n",
    "downsampling = 1e-3 # внутренняя метрика модели\n",
    "\n",
    "model = Word2Vec(sentences, workers=num_workers, size=num_features,\n",
    "                 min_count=min_word_count, window=context, sample=downsampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Финализируем нашу модель. Ее нельзя будет доучить теперь, но она начнет занимать гораздо меньше места\n",
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'beer', 0.6807037591934204),\n",
       " (u'champagne', 0.6553428769111633),\n",
       " (u'coffee', 0.6497250199317932),\n",
       " (u'puking', 0.641952395439148),\n",
       " (u'sipping', 0.6341596245765686),\n",
       " (u'booze', 0.627311110496521),\n",
       " (u'smoking', 0.6170046925544739),\n",
       " (u'drinking', 0.6128978729248047),\n",
       " (u'cigarettes', 0.6115179061889648),\n",
       " (u'cigars', 0.6113725900650024)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('vodka')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'berlin'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match(['berlin', 'moscow', 'kz', 'riga', 'utah'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53171"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.index2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def text_to_vec(words, model, size):\n",
    "    text_vec = np.zeros((size,), dtype=\"float32\")\n",
    "    n_words = 0\n",
    "\n",
    "    index2word_set = set(model.index2word)\n",
    "    for word in words:\n",
    "        if word in index2word_set:\n",
    "            n_words = n_words + 1\n",
    "            text_vec = np.add(text_vec, model[word])\n",
    "    \n",
    "    if n_words != 0:\n",
    "        text_vec /= n_words\n",
    "    return text_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def texts_to_vecs(texts, model, size):\n",
    "    texts_vecs = np.zeros((len(texts), size), dtype=\"float32\")\n",
    "    \n",
    "    for i, text in enumerate(texts):\n",
    "        texts_vecs[i] = text_to_vec(text, model, size)\n",
    "\n",
    "    return texts_vecs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_like_word_list = \\\n",
    "[sum(text_to_sentences(text), []) for text in labeled.review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_vecs = texts_to_vecs(train_like_word_list, model, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_like_word_list = \\\n",
    "[sum(text_to_sentences(text), []) for text in test.review]\n",
    "test_vecs = texts_to_vecs(test_like_word_list, model, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=100, n_jobs=8)\n",
    "forest = forest.fit(train_vecs, labeled[\"sentiment\"])\n",
    "predict = forest.predict(test_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48min 41s, sys: 33.3 s, total: 49min 15s\n",
      "Wall time: 1h 41min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Кластеризируем все слова. \n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "word_vectors = model.syn0\n",
    "# Число кластеров установим в 10000. Для этого числа нет \"серебряной пули\". Для каждого случая лучше подойдет разная\n",
    "num_clusters = 1000\n",
    "\n",
    "# Начнем кластеризацию, учитывая что классов много, количество векторов (по сути слов) много,\n",
    "#   все это будет происходит продолжительное время. Можно сходить за чаем.\n",
    "kmeans_clustering = KMeans(n_clusters=num_clusters)\n",
    "idx = kmeans_clustering.fit_predict(word_vectors)\n",
    "\n",
    "# в idx будут храниться номера классов для каждого слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
